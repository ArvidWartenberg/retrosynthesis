{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "#%pip install svgutils\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "files = {e.split(\"-\")[1].split(\".\")[0]: os.getenv(\"HOME\")+\"/data/USTPO/\" \n",
    "         + e for e in os.listdir(os.getenv(\"HOME\")+\"/data/USTPO/\")}\n",
    "with open(files[\"valid\"]) as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line[:-1] for line in lines]\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    rxn = rdChemReactions.ReactionFromSmarts\n",
    "    reaction = rxn(lines[i])\n",
    "    rs = list(reaction.GetReactants())\n",
    "    ps = list(reaction.GetProducts())\n",
    "    title = \"\"\n",
    "    for r in rs:\n",
    "        title += Chem.MolToSmiles(r) + \".\"\n",
    "\n",
    "    title = title[:-1] + \">>\"\n",
    "    for p in ps:\n",
    "        title += Chem.MolToSmiles(r) + \".\"\n",
    "    title = title[:-1]\n",
    "\n",
    "    d = Draw.MolDraw2DSVG(900, 400)\n",
    "    opts = d.drawOptions()        \n",
    "    opts.bgColor = None\n",
    "    opts.clearBackground = False\n",
    "    opts.bondLineWidth = 1\n",
    "    d.DrawReaction(reaction)\n",
    "    d.FinishDrawing()\n",
    "\n",
    "\n",
    "\n",
    "    svg = d.GetDrawingText()\n",
    "    s = svg.replace('svg:','')\n",
    "\n",
    "    import svgutils.transform as sg\n",
    "    fig = sg.fromstring(s)\n",
    "    label = sg.TextElement(450-len(lines[i])*3.2, 80, lines[i], size=11, \n",
    "                           font='sans-serif', anchor='bottom', color='#000000')\n",
    "    fig.append(label)\n",
    "    display(SVG(fig.to_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing\n",
    "# Plotting \n",
    "#%pip install svgutils\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "#phase = \"valid\"\n",
    "for phase in [\"train\", \"valid\", \"test\"]:\n",
    "    files = {e.split(\"-\")[1].split(\".\")[0]: os.getenv(\"HOME\")+\"/data/USTPO/\" \n",
    "             + e for e in os.listdir(os.getenv(\"HOME\")+\"/data/USTPO/\")}\n",
    "    with open(files[phase]) as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "\n",
    "\n",
    "    chars = \" ^#%()+-./0123456789=@ABCDEFGHIKLMNOPRSTVXYZ[\\\\]abcdefgilmnoprstuy$\"\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "    max_len = 160\n",
    "    vacant = \" \"*max_len\n",
    "\n",
    "    lines_out = []\n",
    "    lines_out_ = []\n",
    "    for line in lines:\n",
    "        rs_, ps_ = line.split(\" >> \")\n",
    "        if max(len(rs_),len(ps_)) > max_len: continue\n",
    "        rs_, ps_ = rs_+vacant[len(rs_):], ps_+vacant[len(ps_):]\n",
    "        rs, ps = torch.zeros(max_len),torch.zeros(max_len)\n",
    "        for i in range(max_len): rs[i], ps[i] = char_to_ix[rs_[i]], char_to_ix[ps_[i]]\n",
    "        lines_out.append({\"rs\": rs, \"ps\": ps})\n",
    "        lines_out_.append({\"rs\": rs_, \"ps\": ps_})\n",
    "        #print(rs_)\n",
    "        #print(rs)\n",
    "        #rs = F.one_hot(rs.to(dtype=torch.int64), num_classes=len(chars))\n",
    "        #print(rs)\n",
    "        #print(torch.argmax(rs, axis=1))\n",
    "    \n",
    "    print(\"finished parsing \" + phase)\n",
    "\n",
    "    with open(\"/home/arvid/data/USTPO_text/\"+ phase +\".pickle\", 'wb') as handle:\n",
    "        pickle.dump(lines_out_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d260ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {}\n",
    "for phase in [\"train\", \"valid\", \"test\"]:\n",
    "    with open(\"/home/arvid/data/USTPO_text/\" + phase + \".pickle\", 'rb') as handle:\n",
    "        data[phase] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32974760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys(): print(key + \" \" + str(len(data[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\" ^#%()+-./0123456789=@ABCDEFGHIKLMNOPRSTVXYZ[\\\\]abcdefgilmnoprstuy$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.one_hot(data[\"train\"][100][\"rs\"].to(device, dtype=torch.int64), num_classes=len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ReactionDataset Class\n",
    "# How to shuffle each epoch? Check later.\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ReactionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, split, rep=\" ^#%()+-./0123456789=@ABCDEFGHIKLMNOPRSTVXYZ[\\\\]abcdefgilmnoprstuy$\"):\n",
    "        self.split = split\n",
    "        self.data = data[self.split]\n",
    "        self.rep = rep\n",
    "        # Add augmentation methods here later\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        rs_smiles = self.data[index][\"rs\"]\n",
    "        ps_smiles = self.data[index][\"ps\"]\n",
    "        \n",
    "        # Augment smiles here for train\n",
    "        \n",
    "        rs = \n",
    "        \n",
    "        return {\n",
    "            'rs': F.one_hot(self.data[index][\"rs\"].to(dtype=torch.int64), num_classes=len(self.rep)),\n",
    "            'ps':  F.one_hot(self.data[index][\"ps\"].to(dtype=torch.int64), num_classes=len(self.rep))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    datasets[split] = ReactionDataset(data=data,\n",
    "                                   split=split)\n",
    "\n",
    "    dataloaders[split] = DataLoader(datasets[split],\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=(split != 'test'),\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=False)# Was True before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = datasets[\"train\"].__getitem__(index=100)\n",
    "element[\"rs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01629d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(10, 64, 512)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f137504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ...constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ab76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/arvid/data/USTPO_paper_5x/patents40k_x5MSShuf.csv\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57dad8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input,target\n",
      "\n",
      "[   0    1    2 ... 3997 3998 3999]\n",
      "[3873  494 3565 ... 1005  770 3427]\n",
      "[38730 38730 38730 ... 34270 34270 34270]\n",
      "[38730 38731 38732 ... 34277 34278 34279]\n",
      "30000\n",
      "[38730 38731 38732 ...  4967  4968  4969]\n",
      "[32110 17038  2751 ... 15860 28529 31564]\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/arvid/data/USTPO_paper_5x/patents40k_x5MSShuf.csv\") as f:\n",
    "    lines = f.readlines()\n",
    "import numpy as np\n",
    "print(lines[0])\n",
    "lines = lines[1:]\n",
    "ix = np.arange(0,4000)\n",
    "print(ix)\n",
    "np.random.shuffle(ix)\n",
    "print(ix)\n",
    "ix = np.repeat(ix*10,10)\n",
    "print(ix)\n",
    "ix += np.tile(np.arange(0,10),4000)\n",
    "print(ix)\n",
    "split_ix = int((.75*40000)-(.75*40000)%10)\n",
    "print(split_ix)\n",
    "#data = {\"train\", \"eval\"}\n",
    "#for line in lines[1:]:\n",
    "data = {\"train\": [], \"eval\": []}\n",
    "train_ix = ix[:split_ix]\n",
    "val_ix = ix[split_ix:]\n",
    "print(train_ix)\n",
    "np.random.shuffle(train_ix)\n",
    "np.random.shuffle(val_ix)\n",
    "print(train_ix)\n",
    "print(len(train_ix))\n",
    "\n",
    "for e in train_ix:\n",
    "    splits = lines[e].split(\",\")\n",
    "    #print(splits)\n",
    "    rs = splits[0]\n",
    "    #print(splits[1])\n",
    "    ps = splits[1][:-1]\n",
    "    if max(len(rs),len(ps)) < 160:\n",
    "        data[\"train\"].append({\"rs\": rs, \"ps\": ps})\n",
    "\n",
    "for e in val_ix:\n",
    "    splits = lines[e].split(\",\")\n",
    "    #print(splits)\n",
    "    rs = splits[0]\n",
    "    #print(splits[1])\n",
    "    ps = splits[1][:-1]\n",
    "    if max(len(rs),len(ps)) < 160:\n",
    "        data[\"eval\"].append({\"rs\": rs, \"ps\": ps})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92e613f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rs': '.C(Cl)(=O)C(C)=C.CC(C)(c1cc(cc(C(C)(C)C)c1O)CS)C',\n",
       " 'ps': 'c1(C(C)(C)C)cc(cc(c1O)C(C)(C)C)CSC(C(C)=C)=O'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"eval\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46495fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/arvid/data/USTPO_paper_5x/USTPO_5x_parsed.pickle\", 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
