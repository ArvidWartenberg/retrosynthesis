{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59cc1d2",
   "metadata": {},
   "source": [
    "Notebook for running MNIST classifier, template for working with the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "torch.torch.cuda.set_device(device)\n",
    "print(\"Using device \" + str(torch.torch.cuda.current_device()) + \"/\" + str(torch.cuda.device_count())\n",
    "      +\", name: \" + str(torch.cuda.get_device_name(0)))\n",
    "#device = torch.torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89430492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for loading data\n",
    "#%pip install idx2numpy\n",
    "#%pip install ipywidgets\n",
    "#%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed338da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import idx2numpy\n",
    "data_dir = \"/home/arvid/data/mnist/\"\n",
    "train_imgs = idx2numpy.convert_from_file(data_dir+\"train-images-idx3-ubyte\")\n",
    "train_labels = idx2numpy.convert_from_file(data_dir+\"train-labels-idx1-ubyte\")\n",
    "test_imgs = idx2numpy.convert_from_file(data_dir+\"t10k-images-idx3-ubyte\")\n",
    "test_labels = idx2numpy.convert_from_file(data_dir+\"t10k-labels-idx1-ubyte\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_imgs = torch.tensor(train_imgs, dtype=torch.float64)/255\n",
    "test_imgs = torch.tensor(test_imgs, dtype=torch.float64)/255\n",
    "train_labels = torch.tensor(train_labels,dtype=torch.int32)\n",
    "test_labels = torch.tensor(test_labels,dtype=torch.int32)\n",
    "\n",
    "# Shuffle entire train set\n",
    "if True:\n",
    "    perm = torch.randperm(train_imgs.shape[0])\n",
    "    train_imgs, train_labels = train_imgs[perm,:,:], train_labels[perm]\n",
    "\n",
    "# Place in dict, use 70/30 train eval split\n",
    "num_train = int(train_imgs.shape[0]*0.7)\n",
    "data = {\"train\": {\"images\": train_imgs[:num_train], \"labels\": train_labels[:num_train]},\n",
    "        \"eval\": {\"images\": train_imgs[num_train:], \"labels\": train_labels[num_train:]},\n",
    "        \"test\": {\"images\": test_imgs, \"labels\": test_labels}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataset Class\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, RandomHorizontalFlip, RandomRotation, ToPILImage\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, split, im_size=28):\n",
    "        self.split = split\n",
    "        self.data = data[self.split]\n",
    "        \n",
    "        if split == \"train\":\n",
    "\n",
    "            self.transform = Compose([\n",
    "                Resize((im_size, im_size)),\n",
    "                RandomHorizontalFlip(p=0.5),\n",
    "                RandomRotation(degrees=45),\n",
    "            ])\n",
    "         \n",
    "        elif self.split == \"eval\" or split == \"test\":\n",
    "            self.transform = Compose([\n",
    "                Resize((im_size, im_size)),\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        if split == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize((im_size, im_size)),\n",
    "                RandomHorizontalFlip(p=0.5),\n",
    "                RandomRotation(degrees=45),\n",
    "                ToTensor(),\n",
    "            ])\n",
    "\n",
    "        elif split == 'eval':\n",
    "            self.transform = Compose([\n",
    "                Resize((im_size, im_size)),\n",
    "                ToTensor(),\n",
    "            ])\n",
    "\n",
    "        elif split == 'test':\n",
    "            self.transform = Compose([\n",
    "                Resize((im_size, im_size)),\n",
    "                ToTensor(),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"images\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'image': self.data[\"images\"][index,:,:].clone().detach().unsqueeze(0).tile([3,1,1]).to(dtype=torch.float),\n",
    "            'label': self.data[\"labels\"][index].clone().detach()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99652f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset & dataloader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "for split in ['train', 'eval', 'test']:\n",
    "    datasets[split] = ImageDataset(data=data,\n",
    "                                   split=split)\n",
    "\n",
    "    dataloaders[split] = DataLoader(datasets[split],\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=(split != 'test'),\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=False)# Was True before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True, progress=True)\n",
    "        #print(model)\n",
    "\n",
    "        # Adapt last layer to multi-label task\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=model.fc.in_features, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "        self.base_model = model\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer class\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class Trainer():\n",
    "\n",
    "    @staticmethod\n",
    "    def train_model(model, dataloaders, objective, optimizer, device, run, num_epochs=25):\n",
    "\n",
    "        # Prepare\n",
    "        since = time.time()\n",
    "        best_model_wts = model.state_dict()\n",
    "        best_loss = 999999\n",
    "        running_losses = {'train': [], 'eval': []}\n",
    "        \n",
    "        # Loop\n",
    "        writer = SummaryWriter('runs/mnist/'+run+\"/\")\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Progress\n",
    "            print('\\nEpoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "            for split in ['train', 'eval']:\n",
    "                torch.set_grad_enabled(split == 'train')\n",
    "                model.train(split=='train')\n",
    "                total_loss = 0.0\n",
    "\n",
    "                # Load and train/eval on split\n",
    "                for data in tqdm.tqdm(dataloaders[split],colour='ffffff'):\n",
    "\n",
    "                    # Put batch on device\n",
    "                    inputs, labels = data['image'].to(device), data['label'].to(device, dtype=torch.int64)\n",
    "                    labels = F.one_hot(labels, num_classes=10).to(dtype=torch.float)\n",
    "\n",
    "                    # Forward and calc loss\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = objective(outputs, labels)\n",
    "                    # Backprop if train\n",
    "                    if split == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Record\n",
    "                epoch_loss = total_loss / dataloaders[split].dataset.__len__()\n",
    "                running_losses[split].append(epoch_loss)\n",
    "                print('{} Loss: {:.4f}'.format(split, epoch_loss))\n",
    "                writer.add_scalar('Loss/'+split, epoch_loss, epoch+1)\n",
    "                \n",
    "                # Deep copy if best loss\n",
    "                if split == 'eval' and epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best Validation Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0700550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Init model\n",
    "model = Net(n_classes=10).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "objective = torch.nn.BCELoss()\n",
    "\n",
    "trained_model = Trainer.train_model(model=model,\n",
    "                                    dataloaders=dataloaders,\n",
    "                                    objective=objective,\n",
    "                                    optimizer=optimizer,\n",
    "                                    device=device,\n",
    "                                    run=\"name_of_run\",\n",
    "                                    num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b78a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "torch.save(model.state_dict(),\"/home/arvid/models/mnist/model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3af6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/arvid/code/mnist_test/runs/can_specify/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
